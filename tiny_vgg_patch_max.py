# -*- coding: utf-8 -*-
"""tiny_vgg_patch_max.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1YpXIwnkmeyq2svPaOow_i8sW-SlpNb-E

from google.colab import drive
drive.mount('/content/drive')
"""

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import TensorDataset, DataLoader
from torchvision import datasets, transforms
import numpy as np
import glob
import os
from PIL import Image
from pathlib import Path
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
#import torchmetrics
from sklearn.metrics import accuracy_score
from torch.utils.data import Dataset, Subset
import pickle
from torch.utils.data.sampler import WeightedRandomSampler

from argparse import ArgumentParser
parser = ArgumentParser(description="CNN_MIL")
parser.add_argument("-r", action="store", dest="root", type=str ,help="Root of the x sample folders")
args = parser.parse_args()

device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
#device = torch.device("cpu")
print(f">> Using device: {device}")

# 1. Subclass torch.utils.data.Dataset
class Dataset_Custom(Dataset):

    # 2. Initialize with a targ_dir and transform (optional) parameter
    def __init__(self, root):

        # 1. SAMPLE PATH LIST
        root_all_samples = root + "/*"

        self.device = device
        self.sample_path_list = glob.glob(root_all_samples)
        self.labels = [torch.load(sample)[1] for sample in self.sample_path_list]

    # 5. Overwrite the __len__() method (optional but recommended for subclasses of torch.utils.data.Dataset)
    def __len__(self):
        "Returns the total number of samples."
        return len(self.sample_path_list)

    # 6. Overwrite the __getitem__() method (required for subclasses of torch.utils.data.Dataset)
    def __getitem__(self, sample_idx):
        "Returns one sample of data, data and label (X, y)."

        sample_path = self.sample_path_list[sample_idx]
        input = torch.load(sample_path)

        x_cnn_sample = input[0]
        y_ffnn_sample = input[1]

        return x_cnn_sample, y_ffnn_sample # return data, label (X, y)

#########################################################
# CREATION OF DATASET
#########################################################

#root = "/content/drive/MyDrive/CNN_MIL/input_tensors_dataaug"
root = args.root

dataset = Dataset_Custom(root)

labels = torch.stack(dataset.labels)

train_idx, test_idx = train_test_split(np.arange(len(labels)), test_size=0.2, stratify = labels, random_state=2)

train_dataset = Subset(dataset, indices = train_idx)

test_dataset = Subset(dataset, indices = test_idx)

#########################################################
# CREATION OF DATALOADER
#########################################################

labels_train = labels[train_idx]

labels_train = labels_train.argmax(dim = 1)

class_counts = torch.bincount(labels_train)

# Calculate the sample weights
weights = 1.0 / class_counts[labels_train]

# Create the WeightedRandomSampler
sampler = WeightedRandomSampler(weights, len(weights))

batch_size = 8

# Divide the dataset into batches
dataloader_train = DataLoader(dataset = train_dataset, batch_size = batch_size, sampler = sampler)
dataloader_test = DataLoader(dataset = test_dataset, batch_size = batch_size, shuffle=False)

class net(nn.Module):

    def __init__(self, input_channels, n_filters, k_conv, stride_conv, pad_conv, dilation_conv, bias_conv, k_mpool,
                 stride_mpool, pad_mpool, dilation_mpool, n_input, bias_ffnn, n_output):
        super(net, self).__init__()

        # CNN
        # Build the convolutional neural network architecture

        self.cnn_1 = nn.Sequential(
            nn.Conv2d(in_channels = input_channels,
                      out_channels = n_filters,
                      kernel_size = k_conv,
                      stride = stride_conv,
                      padding = pad_conv,
                      dilation = dilation_conv,
                      bias = bias_conv),

            nn.ReLU(),

            nn.Conv2d(in_channels = n_filters,
                      out_channels = n_filters,
                      kernel_size = k_conv,
                      stride = stride_conv,
                      padding = pad_conv,
                      dilation = dilation_conv,
                      bias = bias_conv),

            nn.ReLU(),

            nn.MaxPool2d(kernel_size= k_mpool,
                         stride = stride_mpool,
                         padding = pad_mpool,
                         dilation = dilation_mpool)
        )

        self.cnn_2 = nn.Sequential(
            nn.Conv2d(in_channels = n_filters,
                      out_channels = n_filters,
                      kernel_size = k_conv,
                      stride = stride_conv,
                      padding = pad_conv,
                      dilation = dilation_conv,
                      bias = bias_conv),

            nn.ReLU(),

            nn.Conv2d(in_channels = n_filters,
                      out_channels = n_filters,
                      kernel_size = k_conv,
                      stride = stride_conv,
                      padding = pad_conv,
                      dilation = dilation_conv,
                      bias = bias_conv),

            nn.ReLU(),

            nn.MaxPool2d(kernel_size= k_mpool,
                         stride = stride_mpool,
                         padding = pad_mpool,
                         dilation = dilation_mpool),

            nn.Flatten()

        )

        # FFNN
        # Build the feed forward neural network architecture

        # Where did this in_features shape come from?
        # It's because each layer of our network compresses and changes the shape of our inputs data.
        self.ffnn = nn.Linear(in_features = n_input,
                              out_features = n_output,
                              bias = bias_ffnn)

    def forward(self, x_cnn):

        x_ffnn_list = list()

        #print("Usage memory before batch", torch.cuda.memory_summary(device=device))

        # Take an individual sample for each batch
        for x_cnn_sample in x_cnn:

          # Apply mean embedding approach to the patch outputs to
          # get a single output for each sample from the convolution
          # part
          y_cnn_embedding, _ = torch.max(self.cnn_2(self.cnn_1(x_cnn_sample)), dim=0)

          # Store each output sample from the convolution part
          x_ffnn_list.append(y_cnn_embedding)


        # The output of the convolution part is the input of the
        # feed forward part for each batch

        x_ffnn = torch.stack(x_ffnn_list)
        #print(x_ffnn)
        #print("Usage memory after CNN part", torch.cuda.memory_summary(device=device))
        # Get the final output for each batch from the feed forward part
        y_ffnn = self.ffnn(x_ffnn)
        #print("Usage memory after batch", torch.cuda.memory_summary(device=device))
        return y_ffnn

def dim_function(input_dim, pad, dil, k, stride):
  output_dim = int(((input_dim + 2 * pad - dil * (k - 1) - 1) / stride) + 1)
  return output_dim

# PREPROCESSING FEATURES
patch_size = train_dataset[0][0].size(2)
input_channels = train_dataset[0][0].size(1)

# CNN features
# Convolutional part
n_filters = 10
k_conv = 3
stride_conv = 1
pad_conv = 1
dilation_conv = 1
bias_conv = True
dim_conv = int(((patch_size + 2 * pad_conv - dilation_conv * (k_conv - 1) - 1) / stride_conv) + 1)

# Max pool layer part
k_mpool = 2
stride_mpool = 2
pad_mpool = 0
dilation_mpool = 1
dim_mpool = int(((dim_conv + 2 * pad_mpool - dilation_mpool * (k_mpool - 1) - 1) / stride_mpool) + 1)

# FFNN features
output_dim_conv_1 = dim_function(patch_size, pad_conv, dilation_conv, k_conv, stride_conv)
output_dim_conv_2 = dim_function(output_dim_conv_1, pad_conv, dilation_conv, k_conv, stride_conv)
output_dim_maxp_1 = dim_function(output_dim_conv_2, pad_mpool, dilation_mpool, k_mpool, stride_mpool)

output_dim_conv_3 = dim_function(output_dim_maxp_1, pad_conv, dilation_conv, k_conv, stride_conv)
output_dim_conv_4 = dim_function(output_dim_conv_3, pad_conv, dilation_conv, k_conv, stride_conv)
output_dim_maxp_2 = dim_function(output_dim_conv_4, pad_mpool, dilation_mpool, k_mpool, stride_mpool)

n_input = output_dim_maxp_2 * output_dim_maxp_2 * n_filters
bias_ffnn = True
n_output = train_dataset[0][1].size(0)

# Build the model using the features
model = net(input_channels, n_filters, k_conv, stride_conv, pad_conv, dilation_conv, bias_conv,
            k_mpool, stride_mpool, pad_mpool, dilation_mpool, n_input, bias_ffnn, n_output).to(device)

# Create an optimizer and loss function
learning_rate = 0.1

optimizer = optim.Adam(model.parameters(), lr=learning_rate)
criterion = nn.CrossEntropyLoss()

def train_test_epoch(dataloader_train, dataloader_test, model, epochs):


  loss_train_list = list()
  loss_test_list = list()

  acc_train_list = list()
  acc_test_list = list()

  prec_train_list = list()
  prec_test_list = list()

  rec_train_list = list()
  rec_test_list = list()

  spec_train_list = list()
  spec_test_list = list()

  for epoch_idx in range(epochs):

    #########################################################
    # TRAIN LOOP
    #########################################################

    batch_loss_train = 0
    y_ffnn_pred_label_list = list()
    y_ffnn_target_label_list = list()

    model.train()
    #print("Usage memory before training step", torch.cuda.memory_summary(device=device))
    for x_cnn_batch, y_ffnn_batch_target in dataloader_train:

      #########################################################
      # GET OUTPUT PREDICTED
      #########################################################
      #print("Usage memory before training step", torch.cuda.memory_summary(device=device))
      # Get the predicted output "y_ffnn_batch_pred" for each batch
      y_ffnn_batch_pred = model(x_cnn_batch.to(device))

      #print("Usage memory after batch training step", torch.cuda.memory_summary(device=device))
      #########################################################
      # LOSS
      #########################################################
      #print("Usage memory before update weights", torch.cuda.memory_summary(device=device))
      # Calculate loss
      loss = criterion(y_ffnn_batch_pred, y_ffnn_batch_target.to(device))
      batch_loss_train += loss.data

      # Apply backpropagation to update parameters (weights and bias)
      loss.backward()
      optimizer.step()
      optimizer.zero_grad()
      #print("Usage memory after update weights", torch.cuda.memory_summary(device=device))
      #########################################################
      # STORE OUTPUT
      #########################################################

      y_ffnn_batch_pred_label = y_ffnn_batch_pred.argmax(dim = 1)
      y_ffnn_batch_target_label = y_ffnn_batch_target.argmax(dim = 1)

      y_ffnn_pred_label_list.append(y_ffnn_batch_pred_label)
      y_ffnn_target_label_list.append(y_ffnn_batch_target_label)

    #########################################################
    # ACCURACY
    #########################################################

    y_ffnn_pred_label = torch.cat(y_ffnn_pred_label_list, dim = 0).cpu().numpy()
    y_ffnn_target_label = torch.cat(y_ffnn_target_label_list, dim = 0).cpu().numpy()

    acc_train, prec_train, rec_train, spec_train = performance_metrics(y_ffnn_pred_label, y_ffnn_target_label)

    ########################################################
    ########################################################
    ########################################################
    ########################################################

    #########################################################
    # TEST LOOP
    #########################################################

    batch_loss_test = 0
    y_ffnn_pred_label_list = list()
    y_ffnn_target_label_list = list()

    model.eval()

    with torch.inference_mode():

      for x_cnn_batch, y_ffnn_batch_target in dataloader_test:

        #########################################################
        # GET OUTPUT PREDICTED
        #########################################################
        #model_cpu = model.to("cpu")
        # Get the predicted output "y_ffnn_batch_pred" for each batch
        y_ffnn_batch_pred = model(x_cnn_batch.to(device))

        #########################################################
        # LOSS
        #########################################################

        # Calculate loss
        loss = criterion(y_ffnn_batch_pred, y_ffnn_batch_target.to(device))
        batch_loss_test += loss.data

        #########################################################
        # STORE OUTPUT
        #########################################################

        y_ffnn_batch_pred_label = y_ffnn_batch_pred.argmax(dim = 1)
        y_ffnn_batch_target_label = y_ffnn_batch_target.argmax(dim = 1)

        y_ffnn_pred_label_list.append(y_ffnn_batch_pred_label)
        y_ffnn_target_label_list.append(y_ffnn_batch_target_label)

      #########################################################
      # ACCURACY
      #########################################################

      y_ffnn_pred_label = torch.cat(y_ffnn_pred_label_list, dim = 0).cpu().numpy()
      y_ffnn_target_label = torch.cat(y_ffnn_target_label_list, dim = 0).cpu().numpy()

      acc_test, prec_test, rec_test, spec_test = performance_metrics(y_ffnn_pred_label, y_ffnn_target_label)

    #########################################################
    # STORE LOSSES AND ACC
    #########################################################

    # Store the train and test loss for each epoch

    loss_train = float(batch_loss_train / len(dataloader_train))
    loss_test = float(batch_loss_test / len(dataloader_test))

    loss_train_list.append(loss_train)
    loss_test_list.append(loss_test)

    # Store the train and test performance metrics for each epoch

    acc_train_list.append(acc_train)
    acc_test_list.append(acc_test)

    prec_train_list.append(prec_train)
    prec_test_list.append(prec_test)

    rec_train_list.append(rec_train)
    rec_test_list.append(rec_test)

    spec_train_list.append(spec_train)
    spec_test_list.append(spec_test)

    print("Epoch:", epoch_idx + 1)
    print("Train loss:", loss_train)
    print("Test loss:", loss_test)
    print("Train accuracy:", acc_train)
    print("Test accuracy:", acc_test)
    print("Train precision:", prec_train)
    print("Test precision:", prec_test)
    print("Train recall:", rec_train)
    print("Test recall:", rec_test)
    print("Train specificity:", spec_train)
    print("Test specificity:", spec_test)

  return model, loss_train_list, loss_test_list, acc_train_list, acc_test_list, prec_train_list, prec_test_list, rec_train_list, rec_test_list, spec_train_list, spec_test_list

def performance_metrics(pred, target):

  # Calculate TP, TN, FP, FN
  TP = np.sum(np.logical_and(pred == 1, target == 1))
  TN = np.sum(np.logical_and(pred == 0, target == 0))
  FP = np.sum(np.logical_and(pred == 1, target == 0))
  FN = np.sum(np.logical_and(pred == 0, target == 1))

  # Calculate metrics
  accuracy = (TP + TN) / (TP + TN + FP + FN)
  precision = TP / (TP + FP)
  recall = TP / (TP + FN)
  specificity = TN / (TN + FP)

  return accuracy, precision, recall, specificity

def plot_function(train_metric, test_metric, metric):

    plt.figure(figsize=(15,4))
    plt.plot(list(range(1, len(train_metric) + 1)), train_metric, label='Training ' + metric)
    plt.plot(list(range(1, len(test_metric) + 1)), test_metric, label='Testing ' + metric)

    # Select range x axis
    # plt.xticks([1, 2, 3, 4, 5], [1, 2, 3, 4, 5])

    # find position of lowest test loss
    minposs = test_metric.index(min(test_metric)) + 1
    plt.axvline(minposs, linestyle='--', color='r',label='Minimum Test ' + metric)

    plt.title("Plot " + metric + " of each epoch")
    plt.legend(frameon=False)
    plt.xlabel('Epochs')
    plt.ylabel(metric)
    plt.show()

epochs = 100

model, train_loss, test_loss, train_acc, test_acc, train_prec, test_prec, train_rec, test_rec, train_spec, test_spec = train_test_epoch(dataloader_train, dataloader_test, model, epochs)

# Create a dictionary to store tensors and the model
data_dict = {
    "train_loss": train_loss,
    "test_loss": test_loss,
    "train_acc": train_acc,
    "test_acc": test_acc,
    "train_prec": train_prec,
    "test_prec": test_prec,
    "train_rec": train_rec,
    "test_rec": test_rec,
    "train_spec": train_spec,
    "test_spec": test_spec,
    "model": model.state_dict()
}

# Save the dictionary in a .pth file
torch.save(data_dict, 'tiny_vgg_patch_max.pth')

print("Train loss:", train_loss)
print("Test loss:", test_loss)
print("Train accuracy:", train_loss)
print("Test accuracy:", test_loss)
print("Train precision:", train_prec)
print("Test precision:", test_prec)
print("Train recall:", train_rec)
print("Test recall:", test_rec)
print("Train specificity:", train_spec)
print("Test specificity:", test_spec)

plot_function(train_loss, test_loss, "Loss")
plot_function(train_acc, test_acc, "Accuracy")
plot_function(train_prec, test_prec, "Precision")
plot_function(train_rec, test_rec, "Recall")
plot_function(train_spec, test_spec, "Specificity")